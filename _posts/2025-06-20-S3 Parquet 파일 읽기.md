---
key: jekyll-text-theme
title: 'S3 Parquet 파일 읽기'
excerpt: 'Spark vs Pandas 완벽 비교 😎'
tags: [Spark]
---



# 1. S3 Parquet 파일 읽기

## S3 버킷 구조

**Bucket:** `s3://my-data-lake/sales/year=2024/`

```
├── part-00000.parquet (10GB)
├── part-00001.parquet (10GB)
├── part-00002.parquet (10GB)
...
└── part-00009.parquet (10GB)
```

총 10개 파일 → **총 100GB**



# 2. Spark 동작 과정

```
df = spark.read.parquet("s3a://my-data-lake/sales/year=2024/")
df.filter(df.amount > 1000).groupBy("region").sum().show()
```



## 2-1. Driver: 작업 시작 및 계획 수립

### Driver가 하는 일

#### 1. S3 메타데이터 읽기

- 파일 목록 조회
- 파티션 정보 확인
- Parquet 푸터 읽어 스키마 추론

```
file_list = s3_client.list_objects("s3://my-data-lake/sales/year=2024/")
schema = read_parquet_schema("s3://my-data-lake/.../part-00000.parquet")
```

#### 2. 논리적 실행 계획 생성

```
FileScan parquet → 
Filter (amount > 1000) → 
Aggregate [region] [sum(amount)]
```


## 2-2. Master: 자원 할당

Spark Master는 다음을 수행한다.

1. Driver 요청 수신
    → “10개 Task 실행할 Executor 필요”
2. Worker 상태 확인

```
Worker1: 4 cores  
Worker2: 4 cores  
Worker3: 2 cores
```

1. Executor 생성 및 Task 분배



## 2-3. Worker / Executor: 병렬 데이터 읽기

각 Executor는 자신에게 할당된 파일을 S3에서 병렬로 스트리밍하며 처리.

```
┌────────────────┐ ┌────────────────┐ ┌────────────────┐
│   Executor 1   │ │   Executor 2   │ │   Executor 3   │
│ Task 1,2,3,4   │ │ Task 5,6,7,8   │ │ Task 9,10      │
│ part-0000~0003 │ │ part-0004~0007 │ │ part-0008~0009 │
└────────────────┘ └────────────────┘ └────────────────┘
```

각자:

- S3에서 직접 읽기
- 필터링 수행
- Partial aggregation 진행


## 2-4. Spark에서의 실제 네트워크 트래픽 흐름

| 시간   | 동작                                         |
| ------ | -------------------------------------------- |
| **T0** | Driver가 S3 메타데이터 읽기 (수 KB)          |
| **T1** | Executors가 동시에 S3에서 parsing 시작       |
| **T2** | Executor 로컬에서 필터 & 집계                |
| **T3** | Partial result를 Driver로 전송 (작은 데이터) |
| **T4** | Driver가 최종 결과 합산                      |



# 3. Pandas 로컬 환경에서 동작 과정

```
import pandas as pd
import s3fs

fs = s3fs.S3FileSystem()
df = pd.read_parquet("s3://my-data-lake/sales/year=2024/")
result = df[df['amount'] > 1000].groupby('region')['amount'].sum()
```



## 3-1. Pandas 동작 방식

```
┌─────────────────────────────────┐
│        단일 Python 프로세스       │
│                                 │
│ 1. 파일 목록 조회 (10개)         │
│                                 │
│ 2. 순차 다운로드 & 전체 메모리 로드│
│   part-0000 (10GB) ━━━━━━━▶ RAM │
│   part-0001 (10GB) ━━━━━━━▶ RAM │
│   part-0002 (10GB) ━━━━━━━▶ RAM │
│                 💥 메모리 초과   │
│                                 │
└─────────────────────────────────┘
```

- **단일 프로세스**
- **순차적 읽기**
- **전체 데이터를 Memory로 로드**
- 중간 오류 발생 시 전체 재시도 필요



# 4. 핵심 차이점 (Spark vs Pandas)

## 4-1. 읽기 방식

### Spark — 병렬 스트리밍 읽기

```
Executor1: ██████░░ (part-0000)
Executor2: █████░░░ (part-0004)
Executor3: ████░░░░ (part-0008)
```

> 동시에 여러 파일 처리

### Pandas — 단일 프로세스 전체 로드

```
part-0000 → 완료  
part-0001 → 완료  
part-0002 → 💥 메모리 부족
```


## 4-2. 메모리 사용

### Spark

- Executor는 자신의 task partition만 스트리밍 처리
- 10GB 파일도 **조각(chunk)** 단위로 읽음
- 필터링되며 메모리 사용량 감소
- 전체 100GB 데이터를 메모리에 올릴 필요 없음

### Pandas

```
df = pd.read_parquet("s3://...")  # 100GB 전체 로드
```

- 전체 데이터를 메모리에 올리려 함
- 일반 PC에서는 불가능



## 4-3. 네트워크 사용

- Spark: Executor 여러 개가 **병렬로 S3에서 직접 다운로드**
- Pandas: 단일 프로세스에서 100GB를 순차적으로 다운로드



## 4-4. 장애 처리

### Spark

- Task 실패 시 자동 재시도
- 다른 Executor로 재할당
- 전체 Job은 계속 진행됨

### Pandas

- 중간에 한 파일이라도 실패하면 **전체 작업 다시 시작**



# 5. 결론

| 항목             | Spark         | Pandas              |
| ---------------- | ------------- | ------------------- |
| 데이터 읽기 방식 | 병렬 스트리밍 | 순차 전체 로드      |
| 메모리 효율      | 매우 효율적   | 비효율적            |
| 네트워크         | 병렬 다운로드 | 단일 다운로드       |
| 장애 대응        | 자동 재시도   | 실패 시 전체 재작업 |
| 대용량 처리      | 강함          | 매우 취약           |