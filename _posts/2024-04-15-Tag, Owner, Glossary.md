---
key: jekyll-text-theme
title: 'Tag, Owner, Glossary'
excerpt: ' Datahub Research ğŸ˜'
tags: [Datahub]
---



# Tag, Owner, Glossary 

## ê°œë…

* DataHubì˜ Tag, Owner, GlossaryëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ì¡°ì§í™”í•˜ê³  ê±°ë²„ë„ŒìŠ¤ë¥¼ ê°•í™”í•˜ëŠ” í•µì‹¬ ê¸°ëŠ¥
* ì „ëµì ìœ¼ë¡œ í™œìš©í•˜ë©´ ë°ì´í„° ë°œê²¬ì„±, ì±…ì„ ì†Œì¬, ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸ ì „ë‹¬ì´ í¬ê²Œ í–¥ìƒë¨.

## Tags (íƒœê·¸)

### Tag ì²´ê³„ ì„¤ê³„


```yaml
# tag_taxonomy.yml
# íƒœê·¸ ë¶„ë¥˜ ì²´ê³„

# 1. ë°ì´í„° ë¶„ë¥˜ (Data Classification)
data_classification:
  - PII                    # ê°œì¸ì‹ë³„ì •ë³´
  - Sensitive              # ë¯¼ê°ì •ë³´
  - Confidential           # ê¸°ë°€
  - Internal               # ë‚´ë¶€ìš©
  - Public                 # ê³µê°œ

# 2. ë°ì´í„° í’ˆì§ˆ (Data Quality)
data_quality:
  - Verified               # ê²€ì¦ë¨
  - Needs_Review           # ë¦¬ë·° í•„ìš”
  - Deprecated             # ì‚¬ìš© ì¤‘ë‹¨ ì˜ˆì •
  - Experimental           # ì‹¤í—˜ì 

# 3. ì—…ë°ì´íŠ¸ ì£¼ê¸° (Update Frequency)
update_frequency:
  - Realtime               # ì‹¤ì‹œê°„
  - Hourly                 # ì‹œê°„ë³„
  - Daily                  # ì¼ë³„
  - Weekly                 # ì£¼ë³„
  - Monthly                # ì›”ë³„
  - On_Demand              # ìš”ì²­ ì‹œ

# 4. ì¤‘ìš”ë„ (Criticality)
criticality:
  - Critical               # ë§¤ìš° ì¤‘ìš”
  - High                   # ì¤‘ìš”
  - Medium                 # ë³´í†µ
  - Low                    # ë‚®ìŒ

# 5. ë„ë©”ì¸ (Domain)
domain:
  - Sales                  # ë§¤ì¶œ
  - Marketing              # ë§ˆì¼€íŒ…
  - Finance                # ì¬ë¬´
  - Product                # ìƒí’ˆ
  - Customer               # ê³ ê°

# 6. í™˜ê²½ (Environment)
environment:
  - Production             # ìš´ì˜
  - Staging                # ìŠ¤í…Œì´ì§•
  - Development            # ê°œë°œ
```

### Tag ìƒì„± ë° ê´€ë¦¬


```python
# tag_management.py
from datahub.emitter.rest_emitter import DatahubRestEmitter
from datahub.metadata.schema_classes import (
    TagPropertiesClass,
    GlobalTagsClass,
    TagAssociationClass,
)

emitter = DatahubRestEmitter('http://localhost:8080')

def create_tag(tag_name, description, color_hex="#1890FF"):
    """íƒœê·¸ ìƒì„±"""
    
    tag_urn = f'urn:li:tag:{tag_name}'
    
    properties = TagPropertiesClass(
        name=tag_name,
        description=description,
        colorHex=color_hex,
    )
    
    emitter.emit_mcp(tag_urn, 'tagProperties', properties)
    print(f"Created tag: {tag_name}")

# ë°ì´í„° ë¶„ë¥˜ íƒœê·¸ ìƒì„±
tags_to_create = [
    {
        'name': 'PII',
        'description': 'ê°œì¸ì‹ë³„ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ë°ì´í„°',
        'color': '#FF4D4F',  # ë¹¨ê°•
    },
    {
        'name': 'Sensitive',
        'description': 'ë¯¼ê°í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´',
        'color': '#FFA940',  # ì£¼í™©
    },
    {
        'name': 'Verified',
        'description': 'ë°ì´í„° í’ˆì§ˆì´ ê²€ì¦ë¨',
        'color': '#52C41A',  # ì´ˆë¡
    },
    {
        'name': 'Critical',
        'description': 'ë¹„ì¦ˆë‹ˆìŠ¤ì— ë§¤ìš° ì¤‘ìš”í•œ ë°ì´í„°',
        'color': '#722ED1',  # ë³´ë¼
    },
]

for tag in tags_to_create:
    create_tag(tag['name'], tag['description'], tag['color'])
```

### ìë™ íƒœê¹…

~~~python
# auto_tagging.py
from datahub.ingestion.graph.client import DataHubGraph
from datahub.metadata.schema_classes import GlobalTagsClass, TagAssociationClass
import re

def auto_tag_pii_columns():
    """PII ì»¬ëŸ¼ ìë™ íƒœê¹…"""
    
    graph = DataHubGraph(config=DatahubClientConfig(server='http://localhost:8080'))
    emitter = DatahubRestEmitter('http://localhost:8080')
    
    # PII íŒ¨í„´
    pii_patterns = [
        r'.*email.*',
        r'.*phone.*',
        r'.*ssn.*',
        r'.*social.*security.*',
        r'.*credit.*card.*',
        r'.*passport.*',
        r'.*driver.*license.*',
    ]
    
    # ëª¨ë“  ë°ì´í„°ì…‹ ì¡°íšŒ
    datasets = graph.search(entity_types=['dataset'], query='*', count=1000)
    
    for dataset in datasets:
        dataset_urn = dataset.entity_urn
        
        # ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
        schema = graph.get_aspect(dataset_urn, SchemaMetadataClass)
        
        if not schema:
            continue
        
        # ê° í•„ë“œ í™•ì¸
        for field in schema.fields:
            field_path = field.fieldPath.lower()
            
            # PII íŒ¨í„´ ë§¤ì¹­
            is_pii = any(re.match(pattern, field_path) for pattern in pii_patterns)
            
            if is_pii:
                # í•„ë“œì— PII íƒœê·¸ ì¶”ê°€
                field_urn = f'urn:li:schemaField:({dataset_urn},{field.fieldPath})'
                
                tags = GlobalTagsClass(
                    tags=[TagAssociationClass(tag='urn:li:tag:PII')]
                )
                
                emitter.emit_mcp(field_urn, 'globalTags', tags)
                print(f"Tagged PII: {dataset_urn} - {field.fieldPath}")

# ì‹¤í–‰
auto_tag_pii_columns()

# ì—…ë°ì´íŠ¸ ë¹ˆë„ ê¸°ë°˜ ìë™ íƒœê¹…
def auto_tag_update_frequency():
    """Airflow ìŠ¤ì¼€ì¤„ ê¸°ë°˜ ì—…ë°ì´íŠ¸ ë¹ˆë„ íƒœê¹…"""
    
    graph = DataHubGraph(config=DatahubClientConfig(server='http://localhost:8080'))
    emitter = DatahubRestEmitter('http://localhost:8080')
    
    # Airflow DAG ì¡°íšŒ
    dags = graph.search(entity_types=['dataFlow'], query='*', count=1000)
    
    for dag in dags:
        dag_urn = dag.entity_urn
        
        # DAG ì •ë³´ ì¡°íšŒ
        flow_info = graph.get_aspect(dag_urn, DataFlowInfoClass)
        
        if not flow_info:
            continue
        
        # ìŠ¤ì¼€ì¤„ íŒŒì‹±
        schedule = flow_info.customProperties.get('schedule', '')
        
        # íƒœê·¸ ê²°ì •
        tag = None
        if '@hourly' in schedule or '0 * * * *' in schedule:
            tag = 'Hourly'
        elif '@daily' in schedule or '0 0 * * *' in schedule:
            tag = 'Daily'
        elif '@weekly' in schedule:
            tag = 'Weekly'
        elif '@monthly' in schedule:
            tag = 'Monthly'
        
        if tag:
            tags = GlobalTagsClass(
                tags=[TagAssociationClass(tag=f'urn:li:tag:{tag}')]
            )
            emitter.emit_mcp(dag_urn, 'globalTags', tags)
            print(f"Tagged {tag}: {dag_urn}")
```

### Ownership (ì†Œìœ ì)

#### ì†Œìœ ì íƒ€ì…
```
ì†Œìœ ì ìœ í˜•:
1. Technical Owner (ê¸°ìˆ  ì†Œìœ ì)
   - ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê°œë°œ/ìœ ì§€ë³´ìˆ˜ ë‹´ë‹¹
   - ê¸°ìˆ ì  ì´ìŠˆ í•´ê²°

2. Business Owner (ë¹„ì¦ˆë‹ˆìŠ¤ ì†Œìœ ì)
   - ë°ì´í„° ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸ ì •ì˜
   - ë°ì´í„° í’ˆì§ˆ ê¸°ì¤€ ê²°ì •

3. Data Steward (ë°ì´í„° ìŠ¤íŠœì–´ë“œ)
   - ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ì •ì±… ì§‘í–‰
   - ë©”íƒ€ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬

4. Data Owner (ë°ì´í„° ì†Œìœ ì)
   - ì „ì²´ ì±…ì„ì
   - ì ‘ê·¼ ê¶Œí•œ ìŠ¹ì¸
~~~

### ì†Œìœ ì í• ë‹¹

```python
# ownership_management.py
from datahub.emitter.mce_builder import make_user_urn, make_group_urn
from datahub.metadata.schema_classes import (
    OwnershipClass,
    OwnerClass,
    OwnershipTypeClass,
)

def assign_owners(dataset_urn, owners_config):
    """ì†Œìœ ì í• ë‹¹"""
    
    emitter = DatahubRestEmitter('http://localhost:8080')
    
    owners = []
    
    for owner_config in owners_config:
        owner_type = owner_config['type']
        owner_id = owner_config['id']
        
        # ì‚¬ìš©ì ë˜ëŠ” ê·¸ë£¹
        if owner_config.get('is_group', False):
            owner_urn = make_group_urn(owner_id)
        else:
            owner_urn = make_user_urn(owner_id)
        
        # ì†Œìœ ì íƒ€ì… ë§¤í•‘
        type_mapping = {
            'technical': OwnershipTypeClass.TECHNICAL_OWNER,
            'business': OwnershipTypeClass.BUSINESS_OWNER,
            'data_steward': OwnershipTypeClass.DATA_STEWARD,
            'data_owner': OwnershipTypeClass.DATAOWNER,
        }
        
        owners.append(
            OwnerClass(
                owner=owner_urn,
                type=type_mapping[owner_type],
            )
        )
    
    ownership = OwnershipClass(owners=owners)
    emitter.emit_mcp(dataset_urn, 'ownership', ownership)

# ì‚¬ìš© ì˜ˆì œ
dataset_urn = 'urn:li:dataset:(urn:li:dataPlatform:snowflake,analytics.sales_summary,PROD)'

assign_owners(dataset_urn, [
    {
        'type': 'data_owner',
        'id': 'sales-team',
        'is_group': True,
    },
    {
        'type': 'technical',
        'id': 'john.doe',
        'is_group': False,
    },
    {
        'type': 'business',
        'id': 'sales-manager',
        'is_group': False,
    },
])
```

### ê·œì¹™ ê¸°ë°˜ ì†Œìœ ì í• ë‹¹

~~~python
# rule_based_ownership.py
import re

def determine_owners(dataset_urn, ownership_rules):
    """ê·œì¹™ ê¸°ë°˜ ì†Œìœ ì ê²°ì •"""
    
    platform, name, env = parse_urn(dataset_urn)
    
    owners = []
    
    for rule in ownership_rules:
        # í”Œë«í¼ ë§¤ì¹­
        if rule.get('platform') and rule['platform'] != platform:
            continue
        
        # ì´ë¦„ íŒ¨í„´ ë§¤ì¹­
        if rule.get('name_pattern'):
            if not re.match(rule['name_pattern'], name):
                continue
        
        # í™˜ê²½ ë§¤ì¹­
        if rule.get('env') and rule['env'] != env:
            continue
        
        # ê·œì¹™ ë§¤ì¹­ ì„±ê³µ - ì†Œìœ ì ì¶”ê°€
        for owner in rule['owners']:
            owners.append({
                'type': owner['type'],
                'id': owner['id'],
                'is_group': owner.get('is_group', False),
            })
    
    return owners

# ì†Œìœ ì ê·œì¹™ ì •ì˜
ownership_rules = [
    {
        'platform': 'snowflake',
        'name_pattern': '.*\\.fact_.*',
        'env': 'PROD',
        'owners': [
            {'type': 'technical', 'id': 'data-engineering', 'is_group': True},
            {'type': 'business', 'id': 'analytics-team', 'is_group': True},
        ],
    },
    {
        'platform': 'snowflake',
        'name_pattern': '.*\\.dim_.*',
        'env': 'PROD',
        'owners': [
            {'type': 'technical', 'id': 'data-engineering', 'is_group': True},
        ],
    },
    {
        'platform': 'mysql',
        'name_pattern': 'sales\\..*',
        'owners': [
            {'type': 'data_owner', 'id': 'sales-team', 'is_group': True},
        ],
    },
]

# ëª¨ë“  ë°ì´í„°ì…‹ì— ì†Œìœ ì í• ë‹¹
def auto_assign_all_owners():
    """ëª¨ë“  ë°ì´í„°ì…‹ì— ê·œì¹™ ê¸°ë°˜ ì†Œìœ ì í• ë‹¹"""
    
    graph = DataHubGraph(config=DatahubClientConfig(server='http://localhost:8080'))
    
    datasets = graph.search(entity_types=['dataset'], query='*', count=1000)
    
    for dataset in datasets:
        dataset_urn = dataset.entity_urn
        
        # ì´ë¯¸ ì†Œìœ ìê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
        ownership = graph.get_aspect(dataset_urn, OwnershipClass)
        if ownership and len(ownership.owners) > 0:
            continue
        
        # ê·œì¹™ ê¸°ë°˜ ì†Œìœ ì ê²°ì •
        owners = determine_owners(dataset_urn, ownership_rules)
        
        if owners:
            assign_owners(dataset_urn, owners)
            print(f"Assigned owners to {dataset_urn}")

auto_assign_all_owners()
```

### Glossary (ìš©ì–´ ì‚¬ì „)

#### Glossary êµ¬ì¡° ì„¤ê³„
```
Business Glossary êµ¬ì¡°:

â”œâ”€â”€ Sales (íŒë§¤)
â”‚   â”œâ”€â”€ Customer (ê³ ê°)
â”‚   â”‚   â”œâ”€â”€ Active Customer (í™œì„± ê³ ê°)
â”‚   â”‚   â”œâ”€â”€ Churn (ì´íƒˆ)
â”‚   â”‚   â””â”€â”€ LTV (ê³ ê° ìƒì•  ê°€ì¹˜)
â”‚   â”œâ”€â”€ Revenue (ë§¤ì¶œ)
â”‚   â”‚   â”œâ”€â”€ Gross Revenue (ì´ ë§¤ì¶œ)
â”‚   â”‚   â”œâ”€â”€ Net Revenue (ìˆœ ë§¤ì¶œ)
â”‚   â”‚   â””â”€â”€ ARR (ì—°ê°„ ë°˜ë³µ ë§¤ì¶œ)
â”‚   â””â”€â”€ Order (ì£¼ë¬¸)
â”‚       â”œâ”€â”€ Conversion Rate (ì „í™˜ìœ¨)
â”‚       â””â”€â”€ AOV (í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡)
â”‚
â”œâ”€â”€ Marketing (ë§ˆì¼€íŒ…)
â”‚   â”œâ”€â”€ Campaign (ìº í˜ì¸)
â”‚   â”œâ”€â”€ CTR (í´ë¦­ë¥ )
â”‚   â”œâ”€â”€ CAC (ê³ ê° íšë“ ë¹„ìš©)
â”‚   â””â”€â”€ ROAS (ê´‘ê³  ìˆ˜ìµë¥ )
â”‚
â””â”€â”€ Product (ìƒí’ˆ)
    â”œâ”€â”€ SKU (ì¬ê³  ê´€ë¦¬ ë‹¨ìœ„)
    â”œâ”€â”€ Category (ì¹´í…Œê³ ë¦¬)
    â””â”€â”€ Inventory (ì¬ê³ )
~~~

### Glossary Term ìƒì„±


```python
# glossary_management.py
from datahub.emitter.mce_builder import make_glossary_term_urn
from datahub.metadata.schema_classes import (
    GlossaryTermInfoClass,
    GlossaryTermsClass,
    GlossaryTermAssociationClass,
)

def create_glossary_term(
    term_id,
    name,
    definition,
    parent_term=None,
    related_terms=None,
    custom_properties=None,
):
    """ìš©ì–´ ì‚¬ì „ í•­ëª© ìƒì„±"""
    
    emitter = DatahubRestEmitter('http://localhost:8080')
    
    term_urn = make_glossary_term_urn(term_id)
    
    term_info = GlossaryTermInfoClass(
        definition=definition,
        name=name,
        termSource='Business Glossary',
        sourceRef=None,
        sourceUrl=None,
        rawSchema=None,
        customProperties=custom_properties or {},
    )
    
    # ìƒìœ„ ìš©ì–´ (ê³„ì¸µ êµ¬ì¡°)
    if parent_term:
        term_info.parentNode = make_glossary_term_urn(parent_term)
    
    # ê´€ë ¨ ìš©ì–´
    if related_terms:
        term_info.relatedTerms = [
            make_glossary_term_urn(rt) for rt in related_terms
        ]
    
    emitter.emit_mcp(term_urn, 'glossaryTermInfo', term_info)
    print(f"Created term: {term_id}")

# ìš©ì–´ ì‚¬ì „ ìƒì„± ì˜ˆì œ
glossary_terms = [
    {
        'id': 'Customer',
        'name': 'ê³ ê°',
        'definition': 'ìš°ë¦¬ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ì œí’ˆì„ êµ¬ë§¤í•œ ê°œì¸ ë˜ëŠ” ê¸°ì—…',
        'custom_properties': {
            'owner': 'sales-team',
            'approved_by': 'cto',
            'approval_date': '2024-01-01',
        },
    },
    {
        'id': 'ActiveCustomer',
        'name': 'í™œì„± ê³ ê°',
        'definition': 'ìµœê·¼ 90ì¼ ì´ë‚´ì— êµ¬ë§¤ ë˜ëŠ” ë¡œê·¸ì¸ ì´ë ¥ì´ ìˆëŠ” ê³ ê°',
        'parent_term': 'Customer',
        'custom_properties': {
            'measurement_period': '90 days',
            'last_updated': '2024-01-15',
        },
    },
    {
        'id': 'Churn',
        'name': 'ê³ ê° ì´íƒˆ',
        'definition': 'í™œì„± ê³ ê°ì—ì„œ ë¹„í™œì„± ê³ ê°ìœ¼ë¡œ ì „í™˜ë˜ëŠ” ê²ƒ. 90ì¼ê°„ í™œë™ì´ ì—†ìœ¼ë©´ ì´íƒˆë¡œ ê°„ì£¼',
        'parent_term': 'Customer',
        'related_terms': ['ActiveCustomer', 'LTV'],
        'custom_properties': {
            'calculation': 'churned_customers / total_customers * 100',
        },
    },
    {
        'id': 'LTV',
        'name': 'ê³ ê° ìƒì•  ê°€ì¹˜',
        'definition': 'í•œ ê³ ê°ì´ ìƒì•  ë™ì•ˆ íšŒì‚¬ì— ê°€ì ¸ë‹¤ì£¼ëŠ” ì´ ë§¤ì¶œ',
        'parent_term': 'Customer',
        'related_terms': ['Revenue', 'Churn'],
        'custom_properties': {
            'formula': 'Average Order Value Ã— Purchase Frequency Ã— Customer Lifespan',
        },
    },
    {
        'id': 'Revenue',
        'name': 'ë§¤ì¶œ',
        'definition': 'ì œí’ˆ ë˜ëŠ” ì„œë¹„ìŠ¤ íŒë§¤ë¡œ ì¸í•œ ìˆ˜ìµ',
    },
    {
        'id': 'GrossRevenue',
        'name': 'ì´ ë§¤ì¶œ',
        'definition': 'í™˜ë¶ˆ, í• ì¸ ë“±ì„ ì°¨ê°í•˜ê¸° ì „ì˜ ì´ íŒë§¤ ê¸ˆì•¡',
        'parent_term': 'Revenue',
    },
    {
        'id': 'NetRevenue',
        'name': 'ìˆœ ë§¤ì¶œ',
        'definition': 'í™˜ë¶ˆ, í• ì¸, ì„¸ê¸ˆ ë“±ì„ ì°¨ê°í•œ í›„ì˜ ì‹¤ì œ ìˆ˜ìµ',
        'parent_term': 'Revenue',
        'related_terms': ['GrossRevenue'],
        'custom_properties': {
            'formula': 'Gross Revenue - Refunds - Discounts - Taxes',
        },
    },
]

for term in glossary_terms:
    create_glossary_term(
        term_id=term['id'],
        name=term['name'],
        definition=term['definition'],
        parent_term=term.get('parent_term'),
        related_terms=term.get('related_terms'),
        custom_properties=term.get('custom_properties'),
    )
```

### ë°ì´í„°ì…‹ì— ìš©ì–´ ì—°ê²°


```python
# link_terms_to_datasets.py

def link_term_to_dataset(dataset_urn, term_ids):
    """ë°ì´í„°ì…‹ì— ìš©ì–´ ì—°ê²°"""
    
    emitter = DatahubRestEmitter('http://localhost:8080')
    
    terms = GlossaryTermsClass(
        terms=[
            GlossaryTermAssociationClass(urn=make_glossary_term_urn(term_id))
            for term_id in term_ids
        ],
        auditStamp=None,
    )
    
    emitter.emit_mcp(dataset_urn, 'glossaryTerms', terms)
    print(f"Linked terms {term_ids} to {dataset_urn}")

# ìë™ ì—°ê²° (ì´ë¦„ ê¸°ë°˜)
def auto_link_terms():
    """ë°ì´í„°ì…‹/ì»¬ëŸ¼ ì´ë¦„ ê¸°ë°˜ ìë™ ìš©ì–´ ì—°ê²°"""
    
    graph = DataHubGraph(config=DatahubClientConfig(server='http://localhost:8080'))
    
    # ìš©ì–´-íŒ¨í„´ ë§¤í•‘
    term_patterns = {
        'Customer': [r'.*customer.*', r'.*user.*', r'.*client.*'],
        'Revenue': [r'.*revenue.*', r'.*sales.*', r'.*income.*'],
        'Order': [r'.*order.*', r'.*purchase.*', r'.*transaction.*'],
        'Product': [r'.*product.*', r'.*item.*', r'.*sku.*'],
    }
    
    datasets = graph.search(entity_types=['dataset'], query='*', count=1000)
    
    for dataset in datasets:
        dataset_urn = dataset.entity_urn
        platform, name, env = parse_urn(dataset_urn)
        
        matched_terms = []
        
        # ë°ì´í„°ì…‹ ì´ë¦„ ë§¤ì¹­
        for term, patterns in term_patterns.items():
            if any(re.match(pattern, name.lower()) for pattern in patterns):
                matched_terms.append(term)
        
        if matched_terms:
            link_term_to_dataset(dataset_urn, matched_terms)

auto_link_terms()
```

## í†µí•© ê±°ë²„ë„ŒìŠ¤ ì›Œí¬í”Œë¡œìš°


```python
# governance_workflow.py

def governance_onboarding(dataset_urn):
    """ìƒˆ ë°ì´í„°ì…‹ì˜ ê±°ë²„ë„ŒìŠ¤ ì˜¨ë³´ë”©"""
    
    print(f"\n=== Governance Onboarding: {dataset_urn} ===\n")
    
    # 1. ìë™ íƒœê¹…
    print("Step 1: Auto-tagging...")
    auto_tags = determine_tags(dataset_urn)
    apply_tags(dataset_urn, auto_tags)
    print(f"  Applied tags: {auto_tags}")
    
    # 2. ì†Œìœ ì í• ë‹¹
    print("Step 2: Assigning owners...")
    owners = determine_owners(dataset_urn, ownership_rules)
    assign_owners(dataset_urn, owners)
    print(f"  Assigned owners: {[o['id'] for o in owners]}")
    
    # 3. ìš©ì–´ ì—°ê²°
    print("Step 3: Linking glossary terms...")
    terms = determine_terms(dataset_urn)
    link_term_to_dataset(dataset_urn, terms)
    print(f"  Linked terms: {terms}")
    
    # 4. í’ˆì§ˆ ì²´í¬
    print("Step 4: Running quality checks...")
    quality_score = run_quality_checks(dataset_urn)
    print(f"  Quality score: {quality_score}")
    
    # 5. ì•Œë¦¼
    print("Step 5: Notifying stakeholders...")
    notify_stakeholders(dataset_urn, owners, tags=auto_tags, quality=quality_score)
    
    print(f"\n=== Onboarding Complete ===\n")

def determine_tags(dataset_urn):
    """ë°ì´í„°ì…‹ì— ì ìš©í•  íƒœê·¸ ê²°ì •"""
    
    graph = DataHubGraph(config=DatahubClientConfig(server='http://localhost:8080'))
    
    tags = []
    
    # ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ íƒœê·¸
    schema = graph.get_aspect(dataset_urn, SchemaMetadataClass)
    if schema:
        for field in schema.fields:
            field_name = field.fieldPath.lower()
            
            # PII ê°ì§€
            if any(pii in field_name for pii in ['email', 'phone', 'ssn', 'passport']):
                tags.append('PII')
                break
    
    # ì´ë¦„ ê¸°ë°˜ íƒœê·¸
    platform, name, env = parse_urn(dataset_urn)
    
    if 'fact_' in name:
        tags.append('Fact_Table')
    elif 'dim_' in name:
        tags.append('Dimension_Table')
    
    if env == 'PROD':
        tags.append('Production')
    
    # ì¤‘ë³µ ì œê±°
    return list(set(tags))

# DataHub Actionsì™€ ì—°ë™
# actions_config.ymlì— ì¶”ê°€:
"""
actions:
  - name: governance_onboarding
    type: custom
    module: governance_workflow
    class: GovernanceOnboardingAction
    event_type: EntityChangeEvent
    event:
      entity_type: dataset
      operation: CREATE
"""
```

## ì ìš© ì‹œ ê³ ë ¤í•´ì•¼ í•  ì 

1. **íƒœê·¸ í‘œì¤€í™”**: ì¡°ì§ ì „ì²´ê°€ ì‚¬ìš©í•  íƒœê·¸ ì²´ê³„ë¥¼ ë¨¼ì € ì •ì˜
2. **ì†Œìœ ì ì±…ì„**: ì†Œìœ ì ì—­í• ê³¼ ì±…ì„ì„ ëª…í™•íˆ ì •ì˜í•˜ê³  ê³µìœ 
3. **ìš©ì–´ ì‚¬ì „ ê´€ë¦¬**: ë¹„ì¦ˆë‹ˆìŠ¤ íŒ€ê³¼ í˜‘ë ¥í•˜ì—¬ ìš©ì–´ ì •ì˜ ì‘ì„±
4. **ìë™í™” ìš°ì„ **: ê°€ëŠ¥í•œ í•œ ìë™ìœ¼ë¡œ íƒœê·¸, ì†Œìœ ì, ìš©ì–´ í• ë‹¹
5. **ì£¼ê¸°ì  ë¦¬ë·°**: ë¶„ê¸°ë³„ë¡œ ë©”íƒ€ë°ì´í„° í’ˆì§ˆ ë¦¬ë·° ìˆ˜í–‰
6. **êµìœ¡**: íŒ€ì›ë“¤ì—ê²Œ ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²• êµìœ¡