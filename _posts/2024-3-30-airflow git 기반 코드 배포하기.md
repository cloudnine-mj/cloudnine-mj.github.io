---
key: jekyll-text-theme
title: 'Airflowì—ì„œ Git ê¸°ë°˜ ì½”ë“œ ë°°í¬'
excerpt: ' Git!! ğŸ˜'
tags: [Airflow]
---

# Airflowì—ì„œ Git ê¸°ë°˜ ì½”ë“œ ë°°í¬

## ê°œë…

* Git-SyncëŠ” Git ì €ì¥ì†Œì˜ DAG íŒŒì¼ì„ ì£¼ê¸°ì ìœ¼ë¡œ ë™ê¸°í™”í•˜ì—¬ Airflowì— ë°°í¬í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜
* CI/CDì™€ í†µí•©í•˜ì—¬ ë²„ì „ ê´€ë¦¬, ì½”ë“œ ë¦¬ë·°, ìë™ ë°°í¬ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŒ.

## ì„¤ì¹˜ (Kubernetes Helm Chart)

```
~~~bash
# values.yamlì— Git-Sync ì„¤ì •
cat > values.yaml <<EOF
dags:
  gitSync:
    enabled: true
    repo: https://github.com/your-org/airflow-dags.git
    branch: main
    rev: HEAD
    depth: 1
    subPath: "dags"
    # SSH Key ì‚¬ìš© (Private Repo)
    sshKeySecret: airflow-ssh-git-secret
    # ë™ê¸°í™” ì£¼ê¸°
    wait: 60  # 60ì´ˆë§ˆë‹¤ ì²´í¬
    # ìê²©ì¦ëª…
    credentialsSecret: git-credentials
    # Known Hosts
    knownHosts: |
      github.com ssh-rsa AAAA...

# SSH Key Secret ìƒì„±
kubectl create secret generic airflow-ssh-git-secret \
  --from-file=gitSshKey=/path/to/id_rsa \
  -n airflow
EOF

helm install airflow apache-airflow/airflow -n airflow -f values.yaml
```

## ì›ë¦¬
1. **Git-Sync ì»¨í…Œì´ë„ˆ**ê°€ Scheduler/Webserver Podì™€ í•¨ê»˜ ì‹¤í–‰ë©ë‹ˆë‹¤.
2. ì£¼ê¸°ì ìœ¼ë¡œ **Git ì €ì¥ì†Œë¥¼ Pull**í•©ë‹ˆë‹¤.
3. DAG íŒŒì¼ì„ **ê³µìœ  ë³¼ë¥¨**ì— ë³µì‚¬í•©ë‹ˆë‹¤.
4. Airflowê°€ **ìƒˆë¡œìš´ DAGë¥¼ ìë™ìœ¼ë¡œ ê°ì§€**í•©ë‹ˆë‹¤.
5. **ë²„ì „ ê´€ë¦¬**ì™€ **ë¡¤ë°±**ì´ ìš©ì´í•©ë‹ˆë‹¤.

## ì½”ë“œ

* ì‹¤ë¬´ì—ì„œ í™œìš©í•œ ì½”ë“œ

### 1. Git ì €ì¥ì†Œ êµ¬ì¡° - í…ŒìŠ¤íŠ¸ìš©

```
airflow-dags/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ production/
â”‚   â”‚   â”œâ”€â”€ daily_etl.py
â”‚   â”‚   â”œâ”€â”€ hourly_sync.py
â”‚   â”‚   â””â”€â”€ weekly_report.py
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ test_pipeline.py
â”‚   â””â”€â”€ common/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ hooks/
â”‚       â”œâ”€â”€ operators/
â”‚       â””â”€â”€ utils.py
â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ custom_operators/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ dags/
â”‚   â””â”€â”€ plugins/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## 2. CI/CD íŒŒì´í”„ë¼ì¸ (GitHub Actions)


```yaml
# .github/workflows/ci.yml
name: Airflow DAG CI/CD

on:
  push:
    branches: [main, staging]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install apache-airflow==2.7.0
          pip install -r requirements.txt
          pip install pytest pylint black
      
      - name: Lint DAGs
        run: |
          pylint dags/ --disable=C,R
          black --check dags/
      
      - name: Test DAG Integrity
        run: |
          python -m pytest tests/dags/test_dag_integrity.py
      
      - name: Test DAG Loading
        run: |
          export AIRFLOW_HOME=$(pwd)
          airflow db init
          python tests/dags/test_dag_loading.py
  
  deploy:
    needs: test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      
      - name: Trigger Airflow Sync
        run: |
          # Git-Syncê°€ ìë™ìœ¼ë¡œ ê°ì§€í•˜ë¯€ë¡œ ë³„ë„ ì•¡ì…˜ ë¶ˆí•„ìš”
          # ë˜ëŠ” Kubernetes Jobìœ¼ë¡œ ì¦‰ì‹œ ë™ê¸°í™” íŠ¸ë¦¬ê±°
          kubectl rollout restart deployment/airflow-scheduler -n airflow
```

### 3. DAG ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸


```python
# tests/dags/test_dag_integrity.py
import pytest
import os
from airflow.models import DagBag

def test_no_import_errors():
    """DAG ë¡œë”© ì‹œ import ì—ëŸ¬ê°€ ì—†ëŠ”ì§€ í™•ì¸"""
    dag_bag = DagBag(dag_folder='dags/', include_examples=False)
    
    assert len(dag_bag.import_errors) == 0, \
        f"DAG import errors: {dag_bag.import_errors}"

def test_all_dags_have_tags():
    """ëª¨ë“  DAGê°€ íƒœê·¸ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸"""
    dag_bag = DagBag(dag_folder='dags/', include_examples=False)
    
    for dag_id, dag in dag_bag.dags.items():
        assert len(dag.tags) > 0, \
            f"DAG {dag_id} has no tags"

def test_all_dags_have_owners():
    """ëª¨ë“  DAGê°€ ì†Œìœ ìë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸"""
    dag_bag = DagBag(dag_folder='dags/', include_examples=False)
    
    for dag_id, dag in dag_bag.dags.items():
        assert dag.default_args.get('owner') is not None, \
            f"DAG {dag_id} has no owner"

def test_no_default_pool():
    """default pool ì‚¬ìš©ì„ ê¸ˆì§€"""
    dag_bag = DagBag(dag_folder='dags/', include_examples=False)
    
    for dag_id, dag in dag_bag.dags.items():
        for task in dag.tasks:
            assert task.pool != 'default_pool', \
                f"Task {task.task_id} in DAG {dag_id} uses default pool"

def test_retries_configured():
    """ëª¨ë“  Taskê°€ ì¬ì‹œë„ ì„¤ì •ì„ ê°€ì§€ëŠ”ì§€ í™•ì¸"""
    dag_bag = DagBag(dag_folder='dags/', include_examples=False)
    
    for dag_id, dag in dag_bag.dags.items():
        for task in dag.tasks:
            assert task.retries is not None and task.retries > 0, \
                f"Task {task.task_id} in DAG {dag_id} has no retry configured"
```

### 4. í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬

```python
# dags/common/config.py
import os

ENVIRONMENT = os.getenv('AIRFLOW_ENV', 'production')

CONFIGS = {
    'production': {
        'database': 'postgresql://prod-db:5432/analytics',
        's3_bucket': 'prod-data-lake',
        'email_recipients': ['data-team@company.com'],
    },
    'staging': {
        'database': 'postgresql://staging-db:5432/analytics',
        's3_bucket': 'staging-data-lake',
        'email_recipients': ['dev-team@company.com'],
    },
    'development': {
        'database': 'postgresql://localhost:5432/analytics',
        's3_bucket': 'dev-data-lake',
        'email_recipients': ['developer@company.com'],
    },
}

def get_config(key):
    """í™˜ê²½ë³„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    return CONFIGS[ENVIRONMENT].get(key)

# dags/daily_etl.py
from common.config import get_config

default_args = {
    'owner': 'data-team',
    'email': get_config('email_recipients'),
}

# Taskì—ì„œ ì‚¬ìš©
def extract_data(**context):
    database_url = get_config('database')
    # ...
```

### 5. DAG Versioning


```python
# dags/versioned_dag.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

# Git Commit Hashë¥¼ DAG IDì— í¬í•¨
GIT_COMMIT = os.getenv('GIT_COMMIT_SHA', 'unknown')[:7]
DAG_VERSION = 'v2.1.0'

dag = DAG(
    f'data_pipeline_{DAG_VERSION}',
    default_args={
        'owner': 'data-team',
        'start_date': datetime(2024, 1, 1),
    },
    schedule_interval='@daily',
    catchup=False,
    tags=['production', DAG_VERSION, GIT_COMMIT],
    # DAG ë¬¸ì„œí™”
    doc_md=f"""
    # Data Pipeline
    
    **Version**: {DAG_VERSION}
    **Git Commit**: {GIT_COMMIT}
    **Last Updated**: {datetime.now().isoformat()}
    
    ## Description
    This DAG processes daily data...
    
    ## Changelog
    - v2.1.0: Added data quality checks
    - v2.0.0: Migrated to new data warehouse
    - v1.0.0: Initial version
    """,
)
```

### 6. ë¡¤ë°± ì „ëµ

```bash
# ì´ì „ ë²„ì „ìœ¼ë¡œ ë¡¤ë°±
git revert HEAD
git push origin main

# ë˜ëŠ” íŠ¹ì • ì»¤ë°‹ìœ¼ë¡œ
git reset --hard <commit-hash>
git push -f origin main

# Kubernetesì—ì„œ ì¦‰ì‹œ ì ìš©
kubectl rollout restart deployment/airflow-scheduler -n airflow
kubectl rollout restart deployment/airflow-webserver -n airflow

# íŠ¹ì • DAGë§Œ pause (ê¸´ê¸‰ ìƒí™©)
airflow dags pause <dag_id>
```

### 7. Branch ì „ëµ

```bash
main (production)
  â† develop (staging)
      â† feature/new-pipeline
      â† hotfix/critical-bug
```

```yaml
# Git-Sync í™˜ê²½ë³„ ì„¤ì •
production:
  branch: main
  
staging:
  branch: develop

# Helm values-production.yaml
dags:
  gitSync:
    branch: main
    
# Helm values-staging.yaml
dags:
  gitSync:
    branch: develop
```

## ì ìš©í•  ë•Œ ê³ ë ¤í•œ ì 

1. **Pre-commit Hooks**: Commit ì „ì— ìë™ìœ¼ë¡œ linting, í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ë³´ê¸°
2. **PR í•„ìˆ˜**: Main ë¸Œëœì¹˜ ì§ì ‘ ì»¤ë°‹ì„ ê¸ˆì§€í•˜ê³ , Pull Request + ì½”ë“œ ë¦¬ë·°ë¥¼ í•„ìˆ˜í™” í•¨.
3. **ìë™í™”ëœ í…ŒìŠ¤íŠ¸**: CIì—ì„œ DAG ë¡œë”©, import ì—ëŸ¬, ì„¤ì • ê²€ì¦ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•˜ë„ë¡ í•¨.
4. **í™˜ê²½ ë¶„ë¦¬**: Production, Staging, Development í™˜ê²½ì„ ë³„ë„ Git ë¸Œëœì¹˜ë¡œ ê´€ë¦¬í•¨.
5. **ë²„ì „ ê´€ë¦¬**: DAGì— ë²„ì „ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì¶”ì  ê°€ëŠ¥ì„±ì„ ë†’ì„.
6. **ë¬¸ì„œí™”**: ê° DAGì˜ ëª©ì , ì†Œìœ ì, ë³€ê²½ ì´ë ¥ì„ DAG íŒŒì¼ ë‚´ì— ë¬¸ì„œí™” í•¨.
7. **Secrets ë¶„ë¦¬**: ë¯¼ê°í•œ ì •ë³´ëŠ” Gitì— ì»¤ë°‹í•˜ì§€ ì•Šê³  Kubernetes Secretì´ë‚˜ Vaultë¥¼ ì‚¬ìš©í•¨.
