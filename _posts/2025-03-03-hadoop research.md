---
key: jekyll-text-theme
title: 'Hadoop 이란?'
excerpt: ' Hadoop study 😎'
tags: [Hadoop]
---

# 1. Hadoop이란 무엇인가?

## 개념

* Hadoop은 Apache 재단에서 개발한 오픈소스 분산 컴퓨팅 플랫폼으로, 대용량 데이터를 여러 대의 서버에 분산 저장하고 병렬 처리할 수 있게 해주는 프레임워크임. 한 대의 컴퓨터로는 처리할 수 없는 수 TB~PB 규모의 데이터를 저렴한 하드웨어 클러스터를 이용해 효율적으로 처리할 수 있음.

## 왜 Hadoop이 필요한가?

**1. 데이터 저장 문제**

- 단일 서버의 디스크 용량으로는 수십 TB의 데이터를 저장할 수 없음
- 고가의 대용량 스토리지 대신 저렴한 서버 여러 대를 활용할 수 있음

**2. 처리 속도 문제**

- 한 대의 CPU로는 대용량 데이터 분석에 며칠이 걸림
- 여러 서버가 동시에 처리하면 시간을 획기적으로 단축할 수 있음

**3. 장애 대응**

- 하드웨어 장애는 언제든 발생할 수 있음
- 데이터를 복제해서 저장하면 장애 시에도 데이터를 보호할 수 있음

## 2. Hadoop의 핵심 구성 요소

## HDFS (Hadoop Distributed File System)

**개념**

* HDFS는 Hadoop의 분산 파일 시스템으로, 대용량 파일을 여러 서버에 나눠서 저장하고 관리하는 시스템임. 일반 파일 시스템과 달리 데이터를 블록 단위로 쪼개서 여러 노드에 분산 저장함.

**주요 특징**

- **블록 기반 저장**: 파일을 128MB 단위의 블록으로 분할
- **데이터 복제**: 각 블록을 기본 3개씩 복제해서 저장
- **장애 허용**: 일부 노드가 고장나도 데이터 유실 없음
- **대용량 파일 최적화**: 수 GB ~ TB 크기의 파일 처리에 효율적

**HDFS 아키텍처**

```
┌─────────────────────────────────────────────────────────┐
│                       NameNode                           │
│              (메타데이터 관리 & 조정자)                    │
│                                                          │
│  - 파일 시스템 네임스페이스 관리                           │
│  - 블록 위치 정보 추적                                    │
│  - 클라이언트 요청 처리                                   │
└─────────────────────────────────────────────────────────┘
                            │
              ┌─────────────┼─────────────┐
              ▼             ▼             ▼
         ┌────────┐    ┌────────┐   ┌────────┐
         │DataNode│    │DataNode│   │DataNode│
         │   #1   │    │   #2   │   │   #3   │
         ├────────┤    ├────────┤   ├────────┤
         │Block 1 │    │Block 1 │   │Block 2 │
         │Block 3 │    │Block 2 │   │Block 3 │
         │Block 5 │    │Block 4 │   │Block 4 │
         └────────┘    └────────┘   └────────┘
```

**동작 원리**

1. 클라이언트가 파일을 HDFS에 쓰기 요청
2. NameNode가 파일을 블록으로 나누고 저장할 DataNode를 결정
3. 각 블록이 여러 DataNode에 복제되어 저장
4. 파일을 읽을 때는 NameNode가 블록 위치를 알려주고 클라이언트가 직접 DataNode에서 읽음

**예시**

1GB 크기의 server.log 파일을 HDFS에 저장하는 경우, 다음과 같은 과정을 거침.

```text
원본 파일 (1GB = 1024MB)이 블록으로 분할됨 (128MB씩)
- Block 1 (128MB)는 DataNode1, DataNode2, DataNode3에 저장됨
- Block 2 (128MB)는 DataNode2, DataNode3, DataNode4에 저장됨
- Block 3 (128MB)는 DataNode1, DataNode3, DataNode5에 저장됨
- Block 4 (128MB)는 DataNode2, DataNode4, DataNode5에 저장됨
- Block 5 (128MB)는 DataNode1, DataNode4, DataNode5에 저장됨
- ...
- Block 8 (128MB)는 DataNode3, DataNode4, DataNode5에 저장됨
```

결과적으로 총 8개의 블록으로 분할되고, 각 블록이 3개씩 복제되어 총 24개의 블록 복사본이 생성됨. 이렇게 하면 DataNode 1대가 고장나도 데이터 보존이 가능함.

## MapReduce

**개념**

MapReduce는 대용량 데이터를 분산 환경에서 병렬로 처리하기 위한 프로그래밍 모델임. 데이터를 여러 조각으로 나눠서 각각 처리한 후(Map), 결과를 모아서 합치는(Reduce) 방식으로 동작함.

**처리 단계**

1. **Map 단계**: 입력 데이터를 키-값 쌍으로 변환
2. **Shuffle & Sort**: 같은 키를 가진 데이터를 그룹화
3. **Reduce 단계**: 그룹화된 데이터를 집계하여 최종 결과 생성

**MapReduce 흐름도**

```
┌─────────────────────────────────────────────────────────┐
│                    입력 데이터 (HDFS)                     │
│     file1.txt    file2.txt    file3.txt    file4.txt    │
└─────────────────────────────────────────────────────────┘
                            │
              ┌─────────────┼─────────────┐
              ▼             ▼             ▼
         ┌────────┐    ┌────────┐   ┌────────┐
         │  Map   │    │  Map   │   │  Map   │
         │ Task 1 │    │ Task 2 │   │ Task 3 │
         └────────┘    └────────┘   └────────┘
              │             │             │
              └─────────────┼─────────────┘
                            ▼
                   ┌─────────────────┐
                   │ Shuffle & Sort  │
                   │  (키별 그룹화)   │
                   └─────────────────┘
                            │
              ┌─────────────┼─────────────┐
              ▼             ▼             ▼
         ┌────────┐    ┌────────┐   ┌────────┐
         │ Reduce │    │ Reduce │   │ Reduce │
         │ Task 1 │    │ Task 2 │   │ Task 3 │
         └────────┘    └────────┘   └────────┘
              │             │             │
              └─────────────┼─────────────┘
                            ▼
┌─────────────────────────────────────────────────────────┐
│                    출력 결과 (HDFS)                       │
│                    result.txt                            │
└─────────────────────────────────────────────────────────┘
```
