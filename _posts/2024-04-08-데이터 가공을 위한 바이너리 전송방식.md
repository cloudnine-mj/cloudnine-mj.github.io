---
key: jekyll-text-theme
title: '데이터 가공을 위한 Binary 전송방식'
excerpt: 'JSON, AVRO 😎'
tags: [KsqlDB, JSON/AVRO, 데이터 가공]
---

# 데이터 가공을 위한 바이너리 전송방식 선택

* 카프카에서 데이터를 전송 할 대 직렬화(serialize)를 통해 바이너리 배열로 변환해야한다. 그 이유는 어떤 값을 참조하는 주소가 담긴 변수를 저장한다고 했을 때, 다시 불러오게 된다고 해도 가리키던 값의 주소가 달라지기 때문에 의미가 없기 때문, 그래서 참조값은 저장하거나 보낼 수 없고 값만 저장하거나 보낼 수 있다.

## JSON

* 스키마가 따로 없이 생성 가능

* 데이터를 보낼 때 전부 보내야하는 불편함이 존재

### Database의 source 테이블 생성

```
mariaDB> create table udf_test (
id int primary key auto_increment, 
c1 int, 
c2 int, 
c3 int, 
c4 int);
```

### Connector 생성

```
curl -XPOST http://192.168.2.52:30099/connectors/
{
    "name": "simple-udf",
    "config": {
        "connector.class" : "io.confluent.connect.jdbc.JdbcSourceConnector",
        "connection.url" : "jdbc:mariadb://mariadb:3306/connectTest",
        "connection.user" : "root",
        "connection.password" : "secret",
        "topic.prefix" : "simple_udf_",
        "mode" : "incrementing",
        "incrementing.column.name" : "id",
        "table.whitelist": "udf_test",
        "topic.creation.default.replication.factor" : 2,
        "topic.creation.default.partitions" : 3,
        "poll.interval.ms" : 2000,
        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter.schemas.enable": "false",
        "key.converter.schemas.enable": "false",
        "max.tasks": 1
    }
}
```

###  데이터를 가져올 stream 생성

```
ksql > create stream test1(
id int key,
c1 int,
c2 int,
c3 int,
c4 int
) with (
kafka_topic='simple_udf_udf_test',
value_format='JSON');

ksql> describe  TEST1;

Name                 : TEST1
 Field | Type                   
--------------------------------
 ID    | INTEGER          (key) 
 C1    | INTEGER                
 C2    | INTEGER                
 C3    | INTEGER                
 C4    | INTEGER                
--------------------------------
```

* 다른 stream을 참조하여 UDF결과를 저장하는 stream 생성

```
#databse에 데이터 insert
MariaDB [connectTest]> insert into udf_test(c1, c2, c3, c4) values(1,2,3,4);
Query OK, 1 row affected (0.00 sec)

MariaDB [connectTest]> insert into udf_test(c1, c2, c3, c4) values(2,3,4,6);
Query OK, 1 row affected (0.02 sec)


#kafka consumer에서 data 확인
[kafka@kafka-cluster-kafka-0 bin]$ ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic simple_udf_udf_test --from-beginning
{"id":17,"c1":1,"c2":2,"c3":3,"c4":4}
{"id":18,"c1":2,"c2":3,"c3":4,"c4":6}

#stream에서 udf 결과 확인
ksql> create stream results AS 
>select TEST_UDF(c1, c2, c3, c4) FROM test2;

 Message                               
---------------------------------------
 Created query with ID CSAS_RESULTS_89 
---------------------------------------
ksql> select * from results EMIT CHANGES;
+-----------------------------------------------------------------------------------------------------------+
|KSQL_COL_0                                                                                                 |
+-----------------------------------------------------------------------------------------------------------+

|2.0                                                                                                        |
|4.0                                                                                                        |

Press CTRL-C to interrupt
```


## AVRO

* schema registry에 schema를 저장하고 데이터를 전송할때 schema의 id만 지정해주면 된다.

