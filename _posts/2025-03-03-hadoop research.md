---
key: jekyll-text-theme
title: 'Hadoop ì´ë€?'
excerpt: ' Hadoop study ğŸ˜'
tags: [Hadoop]
---

# 1. Hadoopì´ë€ ë¬´ì—‡ì¸ê°€?

## ê°œë…

* Hadoopì€ Apache ì¬ë‹¨ì—ì„œ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ë¶„ì‚° ì»´í“¨íŒ… í”Œë«í¼ìœ¼ë¡œ, ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ëŒ€ì˜ ì„œë²„ì— ë¶„ì‚° ì €ì¥í•˜ê³  ë³‘ë ¬ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ì„. í•œ ëŒ€ì˜ ì»´í“¨í„°ë¡œëŠ” ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ìˆ˜ TB~PB ê·œëª¨ì˜ ë°ì´í„°ë¥¼ ì €ë ´í•œ í•˜ë“œì›¨ì–´ í´ëŸ¬ìŠ¤í„°ë¥¼ ì´ìš©í•´ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ.

## ì™œ Hadoopì´ í•„ìš”í•œê°€?

**1. ë°ì´í„° ì €ì¥ ë¬¸ì œ**

- ë‹¨ì¼ ì„œë²„ì˜ ë””ìŠ¤í¬ ìš©ëŸ‰ìœ¼ë¡œëŠ” ìˆ˜ì‹­ TBì˜ ë°ì´í„°ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŒ
- ê³ ê°€ì˜ ëŒ€ìš©ëŸ‰ ìŠ¤í† ë¦¬ì§€ ëŒ€ì‹  ì €ë ´í•œ ì„œë²„ ì—¬ëŸ¬ ëŒ€ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŒ

**2. ì²˜ë¦¬ ì†ë„ ë¬¸ì œ**

- í•œ ëŒ€ì˜ CPUë¡œëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¶„ì„ì— ë©°ì¹ ì´ ê±¸ë¦¼
- ì—¬ëŸ¬ ì„œë²„ê°€ ë™ì‹œì— ì²˜ë¦¬í•˜ë©´ ì‹œê°„ì„ íšê¸°ì ìœ¼ë¡œ ë‹¨ì¶•í•  ìˆ˜ ìˆìŒ

**3. ì¥ì•  ëŒ€ì‘**

- í•˜ë“œì›¨ì–´ ì¥ì• ëŠ” ì–¸ì œë“  ë°œìƒí•  ìˆ˜ ìˆìŒ
- ë°ì´í„°ë¥¼ ë³µì œí•´ì„œ ì €ì¥í•˜ë©´ ì¥ì•  ì‹œì—ë„ ë°ì´í„°ë¥¼ ë³´í˜¸í•  ìˆ˜ ìˆìŒ

## 2. Hadoopì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ

## HDFS (Hadoop Distributed File System)

**ê°œë…**

* HDFSëŠ” Hadoopì˜ ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œìœ¼ë¡œ, ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ì—¬ëŸ¬ ì„œë²„ì— ë‚˜ëˆ ì„œ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œì„. ì¼ë°˜ íŒŒì¼ ì‹œìŠ¤í…œê³¼ ë‹¬ë¦¬ ë°ì´í„°ë¥¼ ë¸”ë¡ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ì—¬ëŸ¬ ë…¸ë“œì— ë¶„ì‚° ì €ì¥í•¨.

**ì£¼ìš” íŠ¹ì§•**

- **ë¸”ë¡ ê¸°ë°˜ ì €ì¥**: íŒŒì¼ì„ 128MB ë‹¨ìœ„ì˜ ë¸”ë¡ìœ¼ë¡œ ë¶„í• 
- **ë°ì´í„° ë³µì œ**: ê° ë¸”ë¡ì„ ê¸°ë³¸ 3ê°œì”© ë³µì œí•´ì„œ ì €ì¥
- **ì¥ì•  í—ˆìš©**: ì¼ë¶€ ë…¸ë“œê°€ ê³ ì¥ë‚˜ë„ ë°ì´í„° ìœ ì‹¤ ì—†ìŒ
- **ëŒ€ìš©ëŸ‰ íŒŒì¼ ìµœì í™”**: ìˆ˜ GB ~ TB í¬ê¸°ì˜ íŒŒì¼ ì²˜ë¦¬ì— íš¨ìœ¨ì 

**HDFS ì•„í‚¤í…ì²˜**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       NameNode                           â”‚
â”‚              (ë©”íƒ€ë°ì´í„° ê´€ë¦¬ & ì¡°ì •ì)                    â”‚
â”‚                                                          â”‚
â”‚  - íŒŒì¼ ì‹œìŠ¤í…œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê´€ë¦¬                           â”‚
â”‚  - ë¸”ë¡ ìœ„ì¹˜ ì •ë³´ ì¶”ì                                     â”‚
â”‚  - í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ ì²˜ë¦¬                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼             â–¼             â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚DataNodeâ”‚    â”‚DataNodeâ”‚   â”‚DataNodeâ”‚
         â”‚   #1   â”‚    â”‚   #2   â”‚   â”‚   #3   â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚Block 1 â”‚    â”‚Block 1 â”‚   â”‚Block 2 â”‚
         â”‚Block 3 â”‚    â”‚Block 2 â”‚   â”‚Block 3 â”‚
         â”‚Block 5 â”‚    â”‚Block 4 â”‚   â”‚Block 4 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ë™ì‘ ì›ë¦¬**

1. í´ë¼ì´ì–¸íŠ¸ê°€ íŒŒì¼ì„ HDFSì— ì“°ê¸° ìš”ì²­
2. NameNodeê°€ íŒŒì¼ì„ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ê³  ì €ì¥í•  DataNodeë¥¼ ê²°ì •
3. ê° ë¸”ë¡ì´ ì—¬ëŸ¬ DataNodeì— ë³µì œë˜ì–´ ì €ì¥
4. íŒŒì¼ì„ ì½ì„ ë•ŒëŠ” NameNodeê°€ ë¸”ë¡ ìœ„ì¹˜ë¥¼ ì•Œë ¤ì£¼ê³  í´ë¼ì´ì–¸íŠ¸ê°€ ì§ì ‘ DataNodeì—ì„œ ì½ìŒ

**ì˜ˆì‹œ**

1GB í¬ê¸°ì˜ server.log íŒŒì¼ì„ HDFSì— ì €ì¥í•˜ëŠ” ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ê±°ì¹¨.

```text
ì›ë³¸ íŒŒì¼ (1GB = 1024MB)ì´ ë¸”ë¡ìœ¼ë¡œ ë¶„í• ë¨ (128MBì”©)
- Block 1 (128MB)ëŠ” DataNode1, DataNode2, DataNode3ì— ì €ì¥ë¨
- Block 2 (128MB)ëŠ” DataNode2, DataNode3, DataNode4ì— ì €ì¥ë¨
- Block 3 (128MB)ëŠ” DataNode1, DataNode3, DataNode5ì— ì €ì¥ë¨
- Block 4 (128MB)ëŠ” DataNode2, DataNode4, DataNode5ì— ì €ì¥ë¨
- Block 5 (128MB)ëŠ” DataNode1, DataNode4, DataNode5ì— ì €ì¥ë¨
- ...
- Block 8 (128MB)ëŠ” DataNode3, DataNode4, DataNode5ì— ì €ì¥ë¨
```

ê²°ê³¼ì ìœ¼ë¡œ ì´ 8ê°œì˜ ë¸”ë¡ìœ¼ë¡œ ë¶„í• ë˜ê³ , ê° ë¸”ë¡ì´ 3ê°œì”© ë³µì œë˜ì–´ ì´ 24ê°œì˜ ë¸”ë¡ ë³µì‚¬ë³¸ì´ ìƒì„±ë¨. ì´ë ‡ê²Œ í•˜ë©´ DataNode 1ëŒ€ê°€ ê³ ì¥ë‚˜ë„ ë°ì´í„° ë³´ì¡´ì´ ê°€ëŠ¥í•¨.

## MapReduce

**ê°œë…**

MapReduceëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë¶„ì‚° í™˜ê²½ì—ì„œ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í”„ë¡œê·¸ë˜ë° ëª¨ë¸ì„. ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ ì„œ ê°ê° ì²˜ë¦¬í•œ í›„(Map), ê²°ê³¼ë¥¼ ëª¨ì•„ì„œ í•©ì¹˜ëŠ”(Reduce) ë°©ì‹ìœ¼ë¡œ ë™ì‘í•¨.

**ì²˜ë¦¬ ë‹¨ê³„**

1. **Map ë‹¨ê³„**: ì…ë ¥ ë°ì´í„°ë¥¼ í‚¤-ê°’ ìŒìœ¼ë¡œ ë³€í™˜
2. **Shuffle & Sort**: ê°™ì€ í‚¤ë¥¼ ê°€ì§„ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”
3. **Reduce ë‹¨ê³„**: ê·¸ë£¹í™”ëœ ë°ì´í„°ë¥¼ ì§‘ê³„í•˜ì—¬ ìµœì¢… ê²°ê³¼ ìƒì„±

**MapReduce íë¦„ë„**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì…ë ¥ ë°ì´í„° (HDFS)                     â”‚
â”‚     file1.txt    file2.txt    file3.txt    file4.txt    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼             â–¼             â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Map   â”‚    â”‚  Map   â”‚   â”‚  Map   â”‚
         â”‚ Task 1 â”‚    â”‚ Task 2 â”‚   â”‚ Task 3 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚             â”‚             â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Shuffle & Sort  â”‚
                   â”‚  (í‚¤ë³„ ê·¸ë£¹í™”)   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼             â–¼             â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Reduce â”‚    â”‚ Reduce â”‚   â”‚ Reduce â”‚
         â”‚ Task 1 â”‚    â”‚ Task 2 â”‚   â”‚ Task 3 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚             â”‚             â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì¶œë ¥ ê²°ê³¼ (HDFS)                       â”‚
â”‚                    result.txt                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pythonìœ¼ë¡œ ì‘ì„±í•œ WordCount ì˜ˆì œ**

* Hadoop Streamingì„ ì´ìš©í•˜ë©´ Pythonìœ¼ë¡œ MapReduce ì‘ì—…ì„ ì‘ì„±í•  ìˆ˜ ìˆìŒ. Hadoop Streamingì€ í‘œì¤€ ì…ì¶œë ¥(stdin/stdout)ì„ í†µí•´ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘í•¨.

**mapper.py**


```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Map í•¨ìˆ˜: ê° ë¼ì¸ì„ ì½ì–´ì„œ ë‹¨ì–´ë³„ë¡œ (ë‹¨ì–´, 1) ìŒì„ ì¶œë ¥
"""
import sys

def mapper():
    # í‘œì¤€ ì…ë ¥ìœ¼ë¡œë¶€í„° í•œ ì¤„ì”© ì½ìŒ
    for line in sys.stdin:
        # ê³µë°± ì œê±°
        line = line.strip()
        # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        words = line.split()
        
        # ê° ë‹¨ì–´ì— ëŒ€í•´ (ë‹¨ì–´, 1) ìŒì„ ì¶œë ¥
        for word in words:
            # íƒ­ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥ (í‚¤\tê°’ í˜•íƒœ)
            print(f"{word}\t1")

if __name__ == "__main__":
    mapper()
```

**reducer.py**


```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Reduce í•¨ìˆ˜: ê°™ì€ ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ í•©ì‚°
"""
import sys
from collections import defaultdict

def reducer():
    word_count = defaultdict(int)
    
    # í‘œì¤€ ì…ë ¥ìœ¼ë¡œë¶€í„° í•œ ì¤„ì”© ì½ìŒ
    for line in sys.stdin:
        # ê³µë°± ì œê±°
        line = line.strip()
        
        # íƒ­ìœ¼ë¡œ êµ¬ë¶„ëœ ë‹¨ì–´ì™€ ê°œìˆ˜ë¥¼ ë¶„ë¦¬
        try:
            word, count = line.split('\t')
            count = int(count)
            # ë‹¨ì–´ë³„ë¡œ ê°œìˆ˜ë¥¼ ëˆ„ì 
            word_count[word] += count
        except ValueError:
            # ì˜ëª»ëœ í˜•ì‹ì˜ ë¼ì¸ì€ ê±´ë„ˆëœ€
            continue
    
    # ê²°ê³¼ ì¶œë ¥
    for word, count in word_count.items():
        print(f"{word}\t{count}")

if __name__ == "__main__":
    reducer()
```

**ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ê¸°**


```bash
# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x mapper.py reducer.py

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
echo "hadoop spark hadoop
spark kafka hadoop
hadoop kafka kafka" > input.txt

# ë¡œì»¬ì—ì„œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
cat input.txt | python3 mapper.py | sort | python3 reducer.py

# ì¶œë ¥ ê²°ê³¼:
# hadoop  4
# kafka   3
# spark   2
```

**Hadoop Streamingìœ¼ë¡œ ì‹¤í–‰í•˜ê¸°**


```bash
# HDFSì— ì…ë ¥ íŒŒì¼ ì—…ë¡œë“œ
hdfs dfs -mkdir -p /user/input
hdfs dfs -put input.txt /user/input/

# Hadoop Streaming ì‘ì—… ì‹¤í–‰
hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \
  -input /user/input/input.txt \
  -output /user/output/wordcount \
  -mapper mapper.py \
  -reducer reducer.py \
  -file mapper.py \
  -file reducer.py

# ê²°ê³¼ í™•ì¸
hdfs dfs -cat /user/output/wordcount/part-00000
```

** ë” íš¨ìœ¨ì ì¸ Reducer ë²„ì „ (ë©”ëª¨ë¦¬ ìµœì í™”)**

```python
python#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Reduce í•¨ìˆ˜: ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬
"""
import sys

def reducer():
    current_word = None
    current_count = 0
    
    # í‘œì¤€ ì…ë ¥ìœ¼ë¡œë¶€í„° í•œ ì¤„ì”© ì½ìŒ (ì´ë¯¸ ì •ë ¬ë˜ì–´ ë“¤ì–´ì˜´)
    for line in sys.stdin:
        line = line.strip()
        
        try:
            word, count = line.split('\t')
            count = int(count)
        except ValueError:
            continue
        
        # ê°™ì€ ë‹¨ì–´ê°€ ê³„ì†ë˜ëŠ” ê²½ìš° ê°œìˆ˜ë§Œ ëˆ„ì 
        if current_word == word:
            current_count += count
        else:
            # ìƒˆë¡œìš´ ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚˜ë©´ ì´ì „ ë‹¨ì–´ì˜ ê²°ê³¼ë¥¼ ì¶œë ¥
            if current_word:
                print(f"{current_word}\t{current_count}")
            current_word = word
            current_count = count
    
    # ë§ˆì§€ë§‰ ë‹¨ì–´ ì¶œë ¥
    if current_word:
        print(f"{current_word}\t{current_count}")

if __name__ == "__main__":
    reducer()
```